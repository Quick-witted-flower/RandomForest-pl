{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d40dc634-bb1e-4c0b-be3c-65deb90e4c86",
   "metadata": {},
   "source": [
    "ETAP 1: Wczytanie danych, przetwarzanie NLP \n",
    " > Wykonujemy wstępne przetwarzanie tekstu: usuwanie interpunkcji, tokenizacja, usuwanie stopwords, lematyzacja.\n",
    " > Dzielimy zbiór na treningowy i testowy (z zachowaniem stratyfikacji).\n",
    " > Dopasowujemy wektoryzator (TfidfVectorizer lub CountVectorizer) tylko na zbiorze treningowym i przekształcamy oba zbiory.\n",
    " > Trenujemy pierwszy model RandomForestClassifier i obliczamy ważność cech (feature_importances_).\n",
    " > Wydrukowanie pierwszych wyników przed selekcją cech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e288c39-7ebd-452a-a4e6-1554df561cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mnkku\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mnkku\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\mnkku\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dokładność modelu: 0.9659\n",
      "Precyzja (Precision): 0.9173\n",
      "Czułość (Recall): 0.8188\n",
      "F1-score: 0.8652\n",
      "\n",
      "Macierz konfuzji:\n",
      "[[955  11]\n",
      " [ 27 122]]\n",
      "\n",
      "Raport klasyfikacji:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       966\n",
      "           1       0.92      0.82      0.87       149\n",
      "\n",
      "    accuracy                           0.97      1115\n",
      "   macro avg       0.94      0.90      0.92      1115\n",
      "weighted avg       0.97      0.97      0.97      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "import string\n",
    "\n",
    "spam_dataset = pd.read_csv('spam.csv', encoding=\"ISO-8859-1\", usecols=[0, 1], names=['Spam', 'Text'], skiprows=1)\n",
    "\n",
    "# Konwersja etykiet na binarne wartości\n",
    "spam_dataset['Spam'] = spam_dataset['Spam'].replace(['ham', 'spam'], [0, 1])\n",
    "\n",
    "# Usuwanie interpunkcji\n",
    "def remove_punctuation(text):\n",
    "    return ''.join([char for char in text if char not in string.punctuation])\n",
    "\n",
    "spam_dataset['Cleaned_Text'] = spam_dataset['Text'].apply(remove_punctuation)\n",
    "\n",
    "# Tokenizacja tekstu\n",
    "nltk.download('punkt')\n",
    "def tokenize(text):\n",
    "    return nltk.word_tokenize(text.lower())\n",
    "\n",
    "spam_dataset['Tokenized_Text'] = spam_dataset['Cleaned_Text'].apply(tokenize)\n",
    "\n",
    "#  Usuwanie stopwords\n",
    "nltk.download('stopwords')\n",
    "stopwords_set = set(stopwords.words(\"english\"))\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    return [word for word in text if word not in stopwords_set]\n",
    "\n",
    "spam_dataset['WithoutStop_Text'] = spam_dataset['Tokenized_Text'].apply(remove_stopwords)\n",
    "\n",
    "#  Lematyzacja\n",
    "nltk.download('wordnet')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatizing(text):\n",
    "    return [lemmatizer.lemmatize(word) for word in text]\n",
    "\n",
    "spam_dataset['Lemmatized_Text'] = spam_dataset['WithoutStop_Text'].apply(lemmatizing)\n",
    "\n",
    "# Podział na zbiór treningowy i testowy (stratyfikacja)\n",
    "X_raw = spam_dataset['Lemmatized_Text'].apply(lambda x: ' '.join(x))\n",
    "y = spam_dataset['Spam']\n",
    "\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(\n",
    "    X_raw, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "#  Dopasowanie wektoryzatora **tylko na zbiorze treningowym**\n",
    "tfidf_vect = TfidfVectorizer(min_df=0.01, max_df=0.5)\n",
    "X_train = tfidf_vect.fit_transform(X_train_raw)\n",
    "X_test = tfidf_vect.transform(X_test_raw)  # Transformujemy testowy zbiór, ale nie dopasowujemy!\n",
    "\n",
    "#  Nauka modelu Random Forest na pełnym zestawie cech\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "#  Feature Importance - istotność cech\n",
    "importances = rf.feature_importances_\n",
    "\n",
    "#  Ocena modelu\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Dokładność modelu: {accuracy:.4f}\")\n",
    "print(f\"Precyzja (Precision): {precision:.4f}\")\n",
    "print(f\"Czułość (Recall): {recall:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")\n",
    "print(\"\\nMacierz konfuzji:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "#  Pełny raport klasyfikacji\n",
    "print(\"\\nRaport klasyfikacji:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0fce9c-1c1e-4b72-829a-e44e05b41bc8",
   "metadata": {},
   "source": [
    "Model na pełnym zbiorze cech osiągnął dokładność 96.59%.\n",
    "🔹 Precyzja: 91.73% | Czułość (Recall): 81.88% | F1-score: 86.52%\n",
    "🔹 Zauważamy, że model ma dobrą ogólną skuteczność, ale recall dla klasy 1 (spam) jest stosunkowo niski (81.88%), co oznacza, że niektóre wiadomości spamowe pozostają niewykryte.\n",
    "🔹  w macierzy konfuzji:\n",
    "TN (True Negative) = 955 → Model poprawnie przewidział 955 wiadomości jako „ham” (nie-spam).\n",
    "FP (False Positive) = 11 → Model błędnie oznaczył 11 wiadomości „ham” jako spam.\n",
    "FN (False Negative) = 27 → Model błędnie oznaczył 27 wiadomości spamowych jako „ham”.\n",
    "TP (True Positive) = 122 → Model poprawnie oznaczył 122 wiadomości jako spam."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4c3a3d-8121-4cfe-8e2e-7dc7e4694a90",
   "metadata": {},
   "source": [
    " ETAP 2 - Spróbujemy ulepszyć model poprzez selekcję cech oraz optymalizację hiperparametrów za pomocą GridSearchCV. Sprawdzimy, czy usunięcie mniej istotnych cech poprawi wyniki i pomoże lepiej klasyfikować spam. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78cd510b-c9bb-422d-a74d-5c1dc47c4069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liczba cech przed selekcją: 132\n",
      "Liczba cech po selekcji: 92\n",
      "Dokładność modelu po selekcji cech: 0.9650\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Selekcja cech o ważności > 0.001\n",
    "important_features = np.where(importances > 0.001)[0]\n",
    "X_train_selected = X_train[:, important_features]\n",
    "X_test_selected = X_test[:, important_features]\n",
    "\n",
    "# Trening nowego modelu na wybranych cechach\n",
    "rf_selected = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_selected.fit(X_train_selected, y_train)\n",
    "\n",
    "# Ocena modelu na zbiorze testowym po selekcji cech\n",
    "accuracy_selected = rf_selected.score(X_test_selected, y_test)\n",
    "\n",
    "# Wydruk wyników przed GridSearch\n",
    "print(f\"Liczba cech przed selekcją: {X_train.shape[1]}\")\n",
    "print(f\"Liczba cech po selekcji: {X_train_selected.shape[1]}\")\n",
    "print(f\"Dokładność modelu po selekcji cech: {accuracy_selected:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357878d6-33a2-4aab-bec9-eda71021547f",
   "metadata": {},
   "source": [
    "Wnioski:\n",
    "\n",
    "    🔹 Usunięcie mniej istotnych cech zmniejszyło liczbę wymiarów z 132 do 92, co sprawia, że model jest szybszy, mniej podatny na przeuczenie i bardziej efektywny obliczeniowo.\n",
    "    🔹 Dokładność modelu minimalnie spadła (z 96.59% do 96.50%), ale model stał się prostszą i bardziej interpretowalną wersją bez utraty istotnej jakości klasyfikacji.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e294145-807a-4499-9ddf-433f9756c2ac",
   "metadata": {},
   "source": [
    " ETAP 3 -  GridSearch (Dobór najlepszych hiperparametrów).\n",
    " \n",
    "Wykonujemy optymalizację hiperparametrów modelu na wybranych cechach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2eee8513-1764-4e9a-82ac-6e48406f6ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Najlepsze hiperparametry: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Dokładność modelu po optymalizacji hiperparametrów: 0.9623\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Grid Search - optymalizacja hiperparametrów\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [5, 10, None],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "#  n_jobs wynosi 1, aby uniknąć problemów z pamięcią\n",
    "grid_search = GridSearchCV(RandomForestClassifier(random_state=42),\n",
    "                           param_grid, cv=5, n_jobs=1)\n",
    "\n",
    "grid_search.fit(X_train_selected, y_train)\n",
    "\n",
    "# Ocena modelu na zbiorze testowym\n",
    "best_model = grid_search.best_estimator_\n",
    "accuracy_optimized = best_model.score(X_test_selected, y_test)\n",
    "\n",
    "#  Wydruk wyników po GridSearch\n",
    "print(f\"Najlepsze hiperparametry: {grid_search.best_params_}\")\n",
    "print(f\"Dokładność modelu po optymalizacji hiperparametrów: {accuracy_optimized:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa48ee3-eb28-41e9-a624-5dec9f3b4e23",
   "metadata": {},
   "source": [
    "Co pakazują najlepsze hiperparametry:\n",
    "\n",
    "max_depth = None → Model nie ma ograniczonej głębokości drzewa, co oznacza, że może się rozwijać do pełnej głębokości, dopóki każda gałąź nie zawiera minimalnej liczby próbek określonej przez min_samples_split.\n",
    "min_samples_split = 5 → Podział węzła nastąpi, jeśli w nim będzie co najmniej 5 próbek (co zapobiega zbyt dużemu dopasowaniu do danych treningowych).\n",
    "n_estimators = 50 → Model używa 50 drzew, co jest najmniejszą wartością testowaną w GridSearch.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465a6b45-c5e9-4431-a260-5b3da4ed2236",
   "metadata": {},
   "source": [
    "Wyniki:\n",
    "\n",
    " > Liczba cech przed selekcją: 132\n",
    " > Liczba cech po selekcji: 92\n",
    "\n",
    " > Dokładność modelu przed GridSearch: 96.50%\n",
    " > Dokładność modelu po optymalizacji hiperparametrów: 96.23%\n",
    "\n",
    "Wnioski:\n",
    " \n",
    "1. Selekcja cech zmniejszyła liczbę atrybutów o ~30%, co przyspiesza trenowanie modelu i zwiększa jego interpretowalność.\n",
    "2. Optymalizacja hiperparametrów lekko obniżyła dokładność (z 96.50% do 96.23%), ale poprawiła stabilność modelu i może zapobiegać przeuczeniu.\n",
    "3. Model skutecznie klasyfikuje wiadomości e-mail jako SPAM/NON-SPAM i jest gotowy do użycia na nowych danych. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (text_processing_env)",
   "language": "python",
   "name": "text_processing_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
