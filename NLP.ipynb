{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd2889c1-d502-4583-aacb-6d8c0bd0a1af",
   "metadata": {},
   "source": [
    "ETAP 1: Wczytanie danych, NLP preprocessing, Wektoryzacja i Feature Importance.\n",
    "\n",
    "        Wydrukowanie pierwszych wyników przed selekcją cech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96afca94-9b25-4682-b4fd-bb5ef4e82614",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mnkku\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mnkku\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\mnkku\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dokładność modelu na pełnym zestawie cech: 0.9677\n",
      "Top 20 cech (słów): ['go', 'great', 'got', 'wat', 'ok', 'free', 'win', 'text', 'txt', 'say', 'already', 'dont', 'think', 'life', 'around', 'hey', 'week', 'back', 'like', 'still']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "spam_dataset = pd.read_csv('spam.csv', encoding=\"ISO-8859-1\", usecols=[0, 1], names=['Spam', 'Text'], skiprows=1)\n",
    "\n",
    "# Konwersja etykiet 'ham' i 'spam' na wartości binarne\n",
    "spam_dataset['Spam'] = spam_dataset['Spam'].replace(['ham', 'spam'], [0, 1])\n",
    "\n",
    "# Usuwanie interpunkcji\n",
    "import string\n",
    "def remove_punctuation(text):\n",
    "    return ''.join([char for char in text if char not in string.punctuation])\n",
    "\n",
    "spam_dataset['Cleaned_Text'] = spam_dataset['Text'].apply(remove_punctuation)\n",
    "\n",
    "# Tokenizacja tekstu\n",
    "nltk.download('punkt')\n",
    "def tokenize(text):\n",
    "    return nltk.word_tokenize(text.lower())\n",
    "\n",
    "spam_dataset['Tokenized_Text'] = spam_dataset['Cleaned_Text'].apply(tokenize)\n",
    "\n",
    "# Usuwanie stopwords\n",
    "nltk.download('stopwords')\n",
    "stopwords_set = set(stopwords.words(\"english\"))\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    return [word for word in text if word not in stopwords_set]\n",
    "\n",
    "spam_dataset['WithoutStop_Text'] = spam_dataset['Tokenized_Text'].apply(remove_stopwords)\n",
    "\n",
    "# Lematyzacja\n",
    "nltk.download('wordnet')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatizing(text):\n",
    "    return [lemmatizer.lemmatize(word) for word in text]\n",
    "\n",
    "spam_dataset['Lemmatized_Text'] = spam_dataset['WithoutStop_Text'].apply(lemmatizing)\n",
    "\n",
    "# Wektoryzacja (CountVectorizer i TfidfVectorizer)**\n",
    "count_vect = CountVectorizer(min_df=0.01, max_df=0.5)\n",
    "tfidf_vect = TfidfVectorizer(min_df=0.01, max_df=0.5)\n",
    "\n",
    "# Konwersja listy tokenów na stringi\n",
    "text_data = spam_dataset['Lemmatized_Text'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# Wektoryzacja\n",
    "X_count = count_vect.fit_transform(text_data)\n",
    "X_tfidf = tfidf_vect.fit_transform(text_data)\n",
    "\n",
    "#  Wybór jednej metody wektoryzacji** (możesz testować obie)\n",
    "X = X_tfidf  # Możesz zamienić na X_count\n",
    "y = spam_dataset['Spam']\n",
    "\n",
    "# Podział zbioru na treningowy i testowy (stratyfikacja)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Nauka modelu Random Forest na pełnym zestawie cech\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Feature Importance - istotność cech\n",
    "importances = rf.feature_importances_\n",
    "\n",
    "#  Wydruk wyników przed selekcją cech\n",
    "print(f\"Dokładność modelu na pełnym zestawie cech: {rf.score(X_test, y_test):.4f}\")\n",
    "print(\"Top 20 cech (słów):\", list(count_vect.vocabulary_.keys())[:20])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bf420a-ea22-40e4-bcff-dab67843f71a",
   "metadata": {},
   "source": [
    "Model na pełnym zbiorze cech osiągnął 96.77% dokładności, sprawdzimy, czy można go ulepszyć poprzez usunięcie mniej istotnych cech i znalezienie optymalnych parametrów za pomocą GridSearchCV."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4c3a3d-8121-4cfe-8e2e-7dc7e4694a90",
   "metadata": {},
   "source": [
    " ETAP 2 -  Selekcja cech i ocena modelu przed GridSearch.\n",
    " \n",
    "Usuwam mniej ważne cechy i sprawdzam, jak wpływa to na dokładność modelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78cd510b-c9bb-422d-a74d-5c1dc47c4069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liczba cech przed selekcją: 129\n",
      "Liczba cech po selekcji: 95\n",
      "Dokładność modelu po selekcji cech: 0.9650\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Selekcja cech o ważności > 0.001\n",
    "important_features = np.where(importances > 0.001)[0]\n",
    "X_train_selected = X_train[:, important_features]\n",
    "X_test_selected = X_test[:, important_features]\n",
    "\n",
    "# Trening nowego modelu na wybranych cechach\n",
    "rf_selected = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_selected.fit(X_train_selected, y_train)\n",
    "\n",
    "# Ocena modelu na zbiorze testowym po selekcji cech\n",
    "accuracy_selected = rf_selected.score(X_test_selected, y_test)\n",
    "\n",
    "# Wydruk wyników przed GridSearch\n",
    "print(f\"Liczba cech przed selekcją: {X_train.shape[1]}\")\n",
    "print(f\"Liczba cech po selekcji: {X_train_selected.shape[1]}\")\n",
    "print(f\"Dokładność modelu po selekcji cech: {accuracy_selected:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357878d6-33a2-4aab-bec9-eda71021547f",
   "metadata": {},
   "source": [
    "Wnioski:\n",
    "\n",
    "     >Usunięcie mniej istotnych cech zmniejszyło liczbę wymiarów z 129 do 95, co sprawia, że model jest szybszy i \n",
    "      bardziej efektywny.\n",
    "     > Dokładność modelu minimalnie spadła (z 96.77% do 96.50%), ale model jest teraz prostszy i bardziej zrozumiały.  \n",
    "     > Możemy teraz przeprowadzić GridSearch, aby sprawdzić, czy dostrojenie hiperparametrów poprawi wynik."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e294145-807a-4499-9ddf-433f9756c2ac",
   "metadata": {},
   "source": [
    " ETAP 3 -  GridSearch (Dobór najlepszych hiperparametrów).\n",
    " \n",
    "Wykonuje optymalizację hiperparametrów modelu na wybranych cechach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2eee8513-1764-4e9a-82ac-6e48406f6ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Najlepsze hiperparametry: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "Dokładność modelu po optymalizacji hiperparametrów: 0.9623\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Grid Search - optymalizacja hiperparametrów\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [5, 10, None],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "#  n_jobs wynosi 1, aby uniknąć problemów z pamięcią\n",
    "grid_search = GridSearchCV(RandomForestClassifier(random_state=42),\n",
    "                           param_grid, cv=5, n_jobs=1)\n",
    "\n",
    "grid_search.fit(X_train_selected, y_train)\n",
    "\n",
    "# Ocena modelu na zbiorze testowym\n",
    "best_model = grid_search.best_estimator_\n",
    "accuracy_optimized = best_model.score(X_test_selected, y_test)\n",
    "\n",
    "#  Wydruk wyników po GridSearch\n",
    "print(f\"Najlepsze hiperparametry: {grid_search.best_params_}\")\n",
    "print(f\"Dokładność modelu po optymalizacji hiperparametrów: {accuracy_optimized:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5816aad9-3a25-4375-9503-c352917b396c",
   "metadata": {},
   "source": [
    "Wyniki i Wnioski : \n",
    "\n",
    "- **Liczba cech przed selekcją**: 129\r\n",
    "- **Liczba cech po selekcji**: 95\r\n",
    "- **Dokładność modelu po selekcji cech**: 96.50%\r\n",
    "- **Najlepsze hiperparametry** po GridSearch:\r\n",
    "  - `max_depth`: None\r\n",
    "  - `min_samples_split`: 2\r\n",
    "  - `n_estimators`: 50\r\n",
    "- **Dokładność modelu po optymalizacji hiperparametrów**:\n",
    "\n",
    "1. **Selekcja cech pozwoliła na zmniejszenie liczby atrybutów o 26%** przy zachowaniu wysokiej dokładności.  \r\n",
    "2. **Optymalizacja hiperparametrów nieco zmniejszyła dokładność, ale poprawiła stabilność modelu**.  \r\n",
    "3. **Model skutecznie klasyfikuje wiadomości e-mail jako SPAM/NON-SPAM i jest gotowy do użycia na nowych danych* 96.23%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (text_processing_env)",
   "language": "python",
   "name": "text_processing_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
