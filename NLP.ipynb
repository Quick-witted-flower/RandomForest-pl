{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d40dc634-bb1e-4c0b-be3c-65deb90e4c86",
   "metadata": {},
   "source": [
    "ETAP 1: Wczytanie danych, przetwarzanie NLP \n",
    " > Wykonujemy wstƒôpne przetwarzanie tekstu: usuwanie interpunkcji, tokenizacja, usuwanie stopwords, lematyzacja.\n",
    " > Dzielimy zbi√≥r na treningowy i testowy (z zachowaniem stratyfikacji).\n",
    " > Dopasowujemy wektoryzator (TfidfVectorizer lub CountVectorizer) tylko na zbiorze treningowym i przekszta≈Çcamy oba zbiory.\n",
    " > Trenujemy pierwszy model RandomForestClassifier i obliczamy wa≈ºno≈õƒá cech (feature_importances_).\n",
    " > Wydrukowanie pierwszych wynik√≥w przed selekcjƒÖ cech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e288c39-7ebd-452a-a4e6-1554df561cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mnkku\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mnkku\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\mnkku\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dok≈Çadno≈õƒá modelu: 0.9659\n",
      "Precyzja (Precision): 0.9173\n",
      "Czu≈Ço≈õƒá (Recall): 0.8188\n",
      "F1-score: 0.8652\n",
      "\n",
      "Macierz konfuzji:\n",
      "[[955  11]\n",
      " [ 27 122]]\n",
      "\n",
      "Raport klasyfikacji:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       966\n",
      "           1       0.92      0.82      0.87       149\n",
      "\n",
      "    accuracy                           0.97      1115\n",
      "   macro avg       0.94      0.90      0.92      1115\n",
      "weighted avg       0.97      0.97      0.97      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "import string\n",
    "\n",
    "spam_dataset = pd.read_csv('spam.csv', encoding=\"ISO-8859-1\", usecols=[0, 1], names=['Spam', 'Text'], skiprows=1)\n",
    "\n",
    "# Konwersja etykiet na binarne warto≈õci\n",
    "spam_dataset['Spam'] = spam_dataset['Spam'].replace(['ham', 'spam'], [0, 1])\n",
    "\n",
    "# Usuwanie interpunkcji\n",
    "def remove_punctuation(text):\n",
    "    return ''.join([char for char in text if char not in string.punctuation])\n",
    "\n",
    "spam_dataset['Cleaned_Text'] = spam_dataset['Text'].apply(remove_punctuation)\n",
    "\n",
    "# Tokenizacja tekstu\n",
    "nltk.download('punkt')\n",
    "def tokenize(text):\n",
    "    return nltk.word_tokenize(text.lower())\n",
    "\n",
    "spam_dataset['Tokenized_Text'] = spam_dataset['Cleaned_Text'].apply(tokenize)\n",
    "\n",
    "#  Usuwanie stopwords\n",
    "nltk.download('stopwords')\n",
    "stopwords_set = set(stopwords.words(\"english\"))\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    return [word for word in text if word not in stopwords_set]\n",
    "\n",
    "spam_dataset['WithoutStop_Text'] = spam_dataset['Tokenized_Text'].apply(remove_stopwords)\n",
    "\n",
    "#  Lematyzacja\n",
    "nltk.download('wordnet')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatizing(text):\n",
    "    return [lemmatizer.lemmatize(word) for word in text]\n",
    "\n",
    "spam_dataset['Lemmatized_Text'] = spam_dataset['WithoutStop_Text'].apply(lemmatizing)\n",
    "\n",
    "# Podzia≈Ç na zbi√≥r treningowy i testowy (stratyfikacja)\n",
    "X_raw = spam_dataset['Lemmatized_Text'].apply(lambda x: ' '.join(x))\n",
    "y = spam_dataset['Spam']\n",
    "\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(\n",
    "    X_raw, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "#  Dopasowanie wektoryzatora **tylko na zbiorze treningowym**\n",
    "tfidf_vect = TfidfVectorizer(min_df=0.01, max_df=0.5)\n",
    "X_train = tfidf_vect.fit_transform(X_train_raw)\n",
    "X_test = tfidf_vect.transform(X_test_raw)  # Transformujemy testowy zbi√≥r, ale nie dopasowujemy!\n",
    "\n",
    "#  Nauka modelu Random Forest na pe≈Çnym zestawie cech\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "#  Feature Importance - istotno≈õƒá cech\n",
    "importances = rf.feature_importances_\n",
    "\n",
    "#  Ocena modelu\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Dok≈Çadno≈õƒá modelu: {accuracy:.4f}\")\n",
    "print(f\"Precyzja (Precision): {precision:.4f}\")\n",
    "print(f\"Czu≈Ço≈õƒá (Recall): {recall:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")\n",
    "print(\"\\nMacierz konfuzji:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "#  Pe≈Çny raport klasyfikacji\n",
    "print(\"\\nRaport klasyfikacji:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0fce9c-1c1e-4b72-829a-e44e05b41bc8",
   "metadata": {},
   "source": [
    "Model na pe≈Çnym zbiorze cech osiƒÖgnƒÖ≈Ç dok≈Çadno≈õƒá 96.59%.\n",
    "üîπ Precyzja: 91.73% | Czu≈Ço≈õƒá (Recall): 81.88% | F1-score: 86.52%\n",
    "üîπ Zauwa≈ºamy, ≈ºe model ma dobrƒÖ og√≥lnƒÖ skuteczno≈õƒá, ale recall dla klasy 1 (spam) jest stosunkowo niski (81.88%), co oznacza, ≈ºe niekt√≥re wiadomo≈õci spamowe pozostajƒÖ niewykryte.\n",
    "üîπ  w macierzy konfuzji:\n",
    "TN (True Negative) = 955 ‚Üí Model poprawnie przewidzia≈Ç 955 wiadomo≈õci jako ‚Äûham‚Äù (nie-spam).\n",
    "FP (False Positive) = 11 ‚Üí Model b≈Çƒôdnie oznaczy≈Ç 11 wiadomo≈õci ‚Äûham‚Äù jako spam.\n",
    "FN (False Negative) = 27 ‚Üí Model b≈Çƒôdnie oznaczy≈Ç 27 wiadomo≈õci spamowych jako ‚Äûham‚Äù.\n",
    "TP (True Positive) = 122 ‚Üí Model poprawnie oznaczy≈Ç 122 wiadomo≈õci jako spam."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4c3a3d-8121-4cfe-8e2e-7dc7e4694a90",
   "metadata": {},
   "source": [
    " ETAP 2 - Spr√≥bujemy ulepszyƒá model poprzez selekcjƒô cech oraz optymalizacjƒô hiperparametr√≥w za pomocƒÖ GridSearchCV. Sprawdzimy, czy usuniƒôcie mniej istotnych cech poprawi wyniki i pomo≈ºe lepiej klasyfikowaƒá spam. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78cd510b-c9bb-422d-a74d-5c1dc47c4069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liczba cech przed selekcjƒÖ: 132\n",
      "Liczba cech po selekcji: 92\n",
      "Dok≈Çadno≈õƒá modelu po selekcji cech: 0.9650\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Selekcja cech o wa≈ºno≈õci > 0.001\n",
    "important_features = np.where(importances > 0.001)[0]\n",
    "X_train_selected = X_train[:, important_features]\n",
    "X_test_selected = X_test[:, important_features]\n",
    "\n",
    "# Trening nowego modelu na wybranych cechach\n",
    "rf_selected = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_selected.fit(X_train_selected, y_train)\n",
    "\n",
    "# Ocena modelu na zbiorze testowym po selekcji cech\n",
    "accuracy_selected = rf_selected.score(X_test_selected, y_test)\n",
    "\n",
    "# Wydruk wynik√≥w przed GridSearch\n",
    "print(f\"Liczba cech przed selekcjƒÖ: {X_train.shape[1]}\")\n",
    "print(f\"Liczba cech po selekcji: {X_train_selected.shape[1]}\")\n",
    "print(f\"Dok≈Çadno≈õƒá modelu po selekcji cech: {accuracy_selected:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357878d6-33a2-4aab-bec9-eda71021547f",
   "metadata": {},
   "source": [
    "Wnioski:\n",
    "\n",
    "    üîπ Usuniƒôcie mniej istotnych cech zmniejszy≈Ço liczbƒô wymiar√≥w z 132 do 92, co sprawia, ≈ºe model jest szybszy, mniej podatny na przeuczenie i bardziej efektywny obliczeniowo.\n",
    "    üîπ Dok≈Çadno≈õƒá modelu minimalnie spad≈Ça (z 96.59% do 96.50%), ale model sta≈Ç siƒô prostszƒÖ i bardziej interpretowalnƒÖ wersjƒÖ bez utraty istotnej jako≈õci klasyfikacji.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e294145-807a-4499-9ddf-433f9756c2ac",
   "metadata": {},
   "source": [
    " ETAP 3 -  GridSearch (Dob√≥r najlepszych hiperparametr√≥w).\n",
    " \n",
    "Wykonujemy optymalizacjƒô hiperparametr√≥w modelu na wybranych cechach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2eee8513-1764-4e9a-82ac-6e48406f6ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Najlepsze hiperparametry: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Dok≈Çadno≈õƒá modelu po optymalizacji hiperparametr√≥w: 0.9623\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Grid Search - optymalizacja hiperparametr√≥w\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [5, 10, None],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "#  n_jobs wynosi 1, aby uniknƒÖƒá problem√≥w z pamiƒôciƒÖ\n",
    "grid_search = GridSearchCV(RandomForestClassifier(random_state=42),\n",
    "                           param_grid, cv=5, n_jobs=1)\n",
    "\n",
    "grid_search.fit(X_train_selected, y_train)\n",
    "\n",
    "# Ocena modelu na zbiorze testowym\n",
    "best_model = grid_search.best_estimator_\n",
    "accuracy_optimized = best_model.score(X_test_selected, y_test)\n",
    "\n",
    "#  Wydruk wynik√≥w po GridSearch\n",
    "print(f\"Najlepsze hiperparametry: {grid_search.best_params_}\")\n",
    "print(f\"Dok≈Çadno≈õƒá modelu po optymalizacji hiperparametr√≥w: {accuracy_optimized:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa48ee3-eb28-41e9-a624-5dec9f3b4e23",
   "metadata": {},
   "source": [
    "Co pakazujƒÖ najlepsze hiperparametry:\n",
    "\n",
    "max_depth = None ‚Üí Model nie ma ograniczonej g≈Çƒôboko≈õci drzewa, co oznacza, ≈ºe mo≈ºe siƒô rozwijaƒá do pe≈Çnej g≈Çƒôboko≈õci, dop√≥ki ka≈ºda ga≈ÇƒÖ≈∫ nie zawiera minimalnej liczby pr√≥bek okre≈õlonej przez min_samples_split.\n",
    "min_samples_split = 5 ‚Üí Podzia≈Ç wƒôz≈Ça nastƒÖpi, je≈õli w nim bƒôdzie co najmniej 5 pr√≥bek (co zapobiega zbyt du≈ºemu dopasowaniu do danych treningowych).\n",
    "n_estimators = 50 ‚Üí Model u≈ºywa 50 drzew, co jest najmniejszƒÖ warto≈õciƒÖ testowanƒÖ w GridSearch.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465a6b45-c5e9-4431-a260-5b3da4ed2236",
   "metadata": {},
   "source": [
    "Wyniki:\n",
    "\n",
    " > Liczba cech przed selekcjƒÖ: 132\n",
    " > Liczba cech po selekcji: 92\n",
    "\n",
    " > Dok≈Çadno≈õƒá modelu przed GridSearch: 96.50%\n",
    " > Dok≈Çadno≈õƒá modelu po optymalizacji hiperparametr√≥w: 96.23%\n",
    "\n",
    "Wnioski:\n",
    " \n",
    "1. Selekcja cech zmniejszy≈Ça liczbƒô atrybut√≥w o ~30%, co przyspiesza trenowanie modelu i zwiƒôksza jego interpretowalno≈õƒá.\n",
    "2. Optymalizacja hiperparametr√≥w lekko obni≈ºy≈Ça dok≈Çadno≈õƒá (z 96.50% do 96.23%), ale poprawi≈Ça stabilno≈õƒá modelu i mo≈ºe zapobiegaƒá przeuczeniu.\n",
    "3. Model skutecznie klasyfikuje wiadomo≈õci e-mail jako SPAM/NON-SPAM i jest gotowy do u≈ºycia na nowych danych. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (text_processing_env)",
   "language": "python",
   "name": "text_processing_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
